{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "TO_hgtmpnFn1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvyAESkBALRf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import gdown\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices('GPU')\n",
        "\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "try:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "1BD_ouKnESel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Collecting GRID dataset"
      ],
      "metadata": {
        "id": "rpmNLgqloApC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#input video\n",
        "url = 'https://drive.google.com/uc?id=1YlvpDLix3S-U8fd-gqRwPcWXAXm8JwjL'\n",
        "output = 'data.zip'\n",
        "gdown.download(url, output, quiet=False)\n",
        "gdown.extractall('data.zip')"
      ],
      "metadata": {
        "id": "6tJNtzyuBvCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocessing"
      ],
      "metadata": {
        "id": "_ERnfr_ToKYQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mouth region image parsing\n",
        "\n",
        "mouthCascade = cv2.CascadeClassifier(\"/content/mouth.xml\")\n",
        "\n",
        "def load_video(path:str):\n",
        "\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    frames = []\n",
        "\n",
        "    for _ in range(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
        "        ret, frame = cap.read()\n",
        "        frame = tf.image.rgb_to_grayscale(frame)\n",
        "        mouth = mouthCascade.detectMultiScale(frame, 1.3, 5)\n",
        "        x, y, w, h = mouth[0]\n",
        "        frames.append(frame[x : x + w, y : y + h, :])       # to find the solution when there are more then one mouth in the video\n",
        "    cap.release()\n",
        "    mean = tf.math.reduce_mean(frames)\n",
        "    std = tf.math.reduce_std(tf.cast(frames, tf.float32))\n",
        "    return tf.cast((frames - mean), tf.float32) / std"
      ],
      "metadata": {
        "id": "ICjL5FCmCM2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_video(\"/content/bbaf2n.mpg\")"
      ],
      "metadata": {
        "id": "dX9D28IPQU0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = [x for x in \"abcdefghijklmnopqrstuvwxyz'?!123456789 \"]\n",
        "char_to_num = tf.keras.layers.StringLookup(vocabulary = vocab, oov_token = \"\")\n",
        "num_to_char = tf.keras.layers.StringLookup(\n",
        "    vocabulary = char_to_num.get_vocabulary(), oov_token = \"\", invert=True\n",
        ")"
      ],
      "metadata": {
        "id": "VxzzC3UQ0xTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_alignments(path:str) -> list[str]:\n",
        "\n",
        "    with open(path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    tokens = []\n",
        "    for line in lines:\n",
        "        line = line.split()\n",
        "        if line[2] != 'sil':\n",
        "            tokens = [*tokens, ' ', line[2]]\n",
        "    return char_to_num(tf.reshape(tf.strings.unicode_split(tokens, input_encoding='UTF-8'), (-1)))[1:]"
      ],
      "metadata": {
        "id": "R-q2Ef62mDTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path: str) -> tuple():\n",
        "\n",
        "    file_name = path.split(\"\\\\\")[-1].split(\".\")[0]\n",
        "    video_path = os.path.join('data', 's1', f'{file_name}.mpg')\n",
        "    alignment_path = os.path.join('data', 'alignments', 's1', f'{file_name}.align')\n",
        "    frames = load_video(video_path)\n",
        "    alignments = load_alignments(alignment_path)\n",
        "    return frames, alignments"
      ],
      "metadata": {
        "id": "WfmcJeSRTpNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mappable_function(path: str) -> list[str]:\n",
        "\n",
        "    result = []\n",
        "    for data in load_data(path):\n",
        "        if data == load_data(path)[0]:\n",
        "            result.append(tf.cast(data, tf.float32))\n",
        "        else:\n",
        "            result.append(tf.cast(data, tf.int64))\n",
        "    return tf.stack(result)"
      ],
      "metadata": {
        "id": "qQ5C5BPdkpdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BjvirPk0CNB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vJmvzbiaCNJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fPUqld5lCYRS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}